{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resources\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, SGDRegressor\n",
    "\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Problem\n",
    "\n",
    "Daily stock market return data are notoriously difficult to predict and forecast given volatiltity due to many possible predictors and underlying interactions.\n",
    "\n",
    "## Goal\n",
    "\n",
    "To predict S&P 500 returns based on news data.\n",
    "\n",
    "## Data\n",
    "\n",
    "Predictors:\n",
    "* Huff Post News Data (https://www.kaggle.com/datasets/rmisra/news-category-dataset)\n",
    "    * **category**: category in which the article was published.\n",
    "    * **headline**: the headline of the news article.\n",
    "    * **authors**: list of authors who contributed to the article.\n",
    "    * **link**: link to the original news article.\n",
    "    * **short_description**: Abstract of the news article.\n",
    "    * **date**: publication date of the article between 2012-01-28 and 2022-09-23\n",
    "\n",
    "Target:\n",
    "* S&P500 Data (https://fred.stlouisfed.org/series/SP500)\n",
    "    * **Returns** (USD) between 2013-06-27 to 2023-06-26\n",
    "\n",
    "\n",
    "Side note: I wish we had timestamps to determine if the headlines on a given date occured before the market closed\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. Data ETL\n",
    "2. Data Pre-Processing\n",
    "3. Text predictor feature extraction\n",
    "4. Feature engineering\n",
    "5. Modeling\n",
    "    * Logistic Regression (baseline prediction)\n",
    "    * Random Forest Regression (ensemble learner prediction)\n",
    "    * Autokeras (out-of-the-box neural net prediction)\n",
    "    * 1D CNN (custom spatio-temportal prediction)\n",
    "    * LSTM (custom time-series prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors\n",
    "news = []\n",
    "with open('News_Category_Dataset_v3.json', 'r') as file:\n",
    "    for line in file:\n",
    "        news.append(json.loads(line))\n",
    "news = pd.DataFrame.from_dict(news)\n",
    "\n",
    "#target\n",
    "returns = pd.read_csv('SP500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209527, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "         date  \n",
       "0  2022-09-23  \n",
       "1  2022-09-23  \n",
       "2  2022-09-23  \n",
       "3  2022-09-23  \n",
       "4  2022-09-22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209527</td>\n",
       "      <td>209527</td>\n",
       "      <td>209527</td>\n",
       "      <td>209527</td>\n",
       "      <td>209527</td>\n",
       "      <td>209527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>209486</td>\n",
       "      <td>207996</td>\n",
       "      <td>42</td>\n",
       "      <td>187022</td>\n",
       "      <td>29169</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.huffingtonpost.comhttps://www.wash...</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2014-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>35602</td>\n",
       "      <td>19712</td>\n",
       "      <td>37418</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link        headline  \\\n",
       "count                                              209527          209527   \n",
       "unique                                             209486          207996   \n",
       "top     https://www.huffingtonpost.comhttps://www.wash...  Sunday Roundup   \n",
       "freq                                                    2              90   \n",
       "\n",
       "        category short_description authors        date  \n",
       "count     209527            209527  209527      209527  \n",
       "unique        42            187022   29169        3890  \n",
       "top     POLITICS                            2014-03-25  \n",
       "freq       35602             19712   37418         100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "link                 object\n",
       "headline             object\n",
       "category             object\n",
       "short_description    object\n",
       "authors              object\n",
       "date                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2608, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>1606.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1614.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>1614.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>1615.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE    SP500\n",
       "0  2013-06-27  1613.20\n",
       "1  2013-06-28  1606.28\n",
       "2  2013-07-01  1614.96\n",
       "3  2013-07-02  1614.08\n",
       "4  2013-07-03  1615.41"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2608</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2608</td>\n",
       "      <td>2504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATE SP500\n",
       "count         2608  2608\n",
       "unique        2608  2504\n",
       "top     2013-06-27     .\n",
       "freq             1    92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DATE     object\n",
       "SP500    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape\n",
    "news.head()\n",
    "news.describe()\n",
    "news.dtypes\n",
    "\n",
    "returns.shape\n",
    "returns.head()\n",
    "returns.describe()\n",
    "returns.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast date columns as datetime types\n",
    "news['date'] = pd.to_datetime(news['date'])\n",
    "\n",
    "returns['DATE'] = pd.to_datetime(returns['DATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE     datetime64[ns]\n",
       "SP500           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast returns column as float\n",
    "returns['SP500'] = pd.to_numeric(returns['SP500'], errors='coerce')\n",
    "\n",
    "returns.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a decision to drop authors and link as predictors. Authors write on certain topics and do not work indefinitely for the company, the links are based on the titles; there is a co-effect or colinearity between category and author, and description/title and link so we try to reduce multicollinearity right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4242162910.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['returns'] = data['date'].map(di)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>3757.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>TECH</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>2012-01-28</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date   category  \\\n",
       "0      2022-09-23  U.S. NEWS   \n",
       "1      2022-09-23  U.S. NEWS   \n",
       "2      2022-09-23     COMEDY   \n",
       "3      2022-09-23  PARENTING   \n",
       "4      2022-09-22  U.S. NEWS   \n",
       "...           ...        ...   \n",
       "209522 2012-01-28       TECH   \n",
       "209523 2012-01-28     SPORTS   \n",
       "209524 2012-01-28     SPORTS   \n",
       "209525 2012-01-28     SPORTS   \n",
       "209526 2012-01-28     SPORTS   \n",
       "\n",
       "                                                 headline  \\\n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1       American Airlines Flyer Charged, Banned For Li...   \n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3       The Funniest Tweets From Parents This Week (Se...   \n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...                                                   ...   \n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  returns  \n",
       "0       Health experts said it is too early to predict...  3693.23  \n",
       "1       He was subdued by passengers and crew when he ...  3693.23  \n",
       "2       \"Until you have a dog you don't understand wha...  3693.23  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  3693.23  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  3757.99  \n",
       "...                                                   ...      ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...      NaN  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...      NaN  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...      NaN  \n",
       "209525  CORRECTION: An earlier version of this story i...      NaN  \n",
       "209526  The five-time all-star center tore into his te...      NaN  \n",
       "\n",
       "[209527 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = news[['date', 'category', 'headline', 'short_description']]\n",
    "\n",
    "#map target to predictors using date\n",
    "di = dict(zip(returns.DATE, returns.SP500))\n",
    "\n",
    "data['returns'] = data['date'].map(di)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>3693.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>3757.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161346</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>Cheryl Cole's Style Evolution: From Cornrows T...</td>\n",
       "      <td>Cheryl Cole's path to fame wasn't exactly ordi...</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161347</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>Three of Europe's Most Hedonistic Cities: Part...</td>\n",
       "      <td>Paris brings us back again and again, season a...</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161348</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Anxiety Tied To Sleep Deprivation</td>\n",
       "      <td>\"It's been hard to tease out whether sleep los...</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161349</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>FOOD &amp; DRINK</td>\n",
       "      <td>Mac And Cheese Creations: Over The Top And Com...</td>\n",
       "      <td>You can add this dish to just about everything.</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161350</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Stopping to Recognize Live-Out-Loud Joy as You...</td>\n",
       "      <td>When I look back now, did I stop to recognize ...</td>\n",
       "      <td>1613.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date        category  \\\n",
       "0      2022-09-23       U.S. NEWS   \n",
       "1      2022-09-23       U.S. NEWS   \n",
       "2      2022-09-23          COMEDY   \n",
       "3      2022-09-23       PARENTING   \n",
       "4      2022-09-22       U.S. NEWS   \n",
       "...           ...             ...   \n",
       "161346 2013-06-27  STYLE & BEAUTY   \n",
       "161347 2013-06-27          TRAVEL   \n",
       "161348 2013-06-27        WELLNESS   \n",
       "161349 2013-06-27    FOOD & DRINK   \n",
       "161350 2013-06-27        WELLNESS   \n",
       "\n",
       "                                                 headline  \\\n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1       American Airlines Flyer Charged, Banned For Li...   \n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3       The Funniest Tweets From Parents This Week (Se...   \n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...                                                   ...   \n",
       "161346  Cheryl Cole's Style Evolution: From Cornrows T...   \n",
       "161347  Three of Europe's Most Hedonistic Cities: Part...   \n",
       "161348                  Anxiety Tied To Sleep Deprivation   \n",
       "161349  Mac And Cheese Creations: Over The Top And Com...   \n",
       "161350  Stopping to Recognize Live-Out-Loud Joy as You...   \n",
       "\n",
       "                                        short_description  returns  \n",
       "0       Health experts said it is too early to predict...  3693.23  \n",
       "1       He was subdued by passengers and crew when he ...  3693.23  \n",
       "2       \"Until you have a dog you don't understand wha...  3693.23  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  3693.23  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  3757.99  \n",
       "...                                                   ...      ...  \n",
       "161346  Cheryl Cole's path to fame wasn't exactly ordi...  1613.20  \n",
       "161347  Paris brings us back again and again, season a...  1613.20  \n",
       "161348  \"It's been hard to tease out whether sleep los...  1613.20  \n",
       "161349    You can add this dish to just about everything.  1613.20  \n",
       "161350  When I look back now, did I stop to recognize ...  1613.20  \n",
       "\n",
       "[118829 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop any rows with empty values in the target column\n",
    "data = data[data['returns'].notna()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-06-27 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-09-23 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check date range after drop\n",
    "data.date.min()\n",
    "data.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\793595985.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['corpus'] = data['headline'] + ' ' + data['short_description']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>returns</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>3757.99</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   category                                           headline  \\\n",
       "0 2022-09-23  U.S. NEWS  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1 2022-09-23  U.S. NEWS  American Airlines Flyer Charged, Banned For Li...   \n",
       "2 2022-09-23     COMEDY  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3 2022-09-23  PARENTING  The Funniest Tweets From Parents This Week (Se...   \n",
       "4 2022-09-22  U.S. NEWS  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "\n",
       "                                   short_description  returns  \\\n",
       "0  Health experts said it is too early to predict...  3693.23   \n",
       "1  He was subdued by passengers and crew when he ...  3693.23   \n",
       "2  \"Until you have a dog you don't understand wha...  3693.23   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...  3693.23   \n",
       "4  Amy Cooper accused investment firm Franklin Te...  3757.99   \n",
       "\n",
       "                                              corpus  \n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  \n",
       "1  American Airlines Flyer Charged, Banned For Li...  \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...  \n",
       "3  The Funniest Tweets From Parents This Week (Se...  \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add a combined corpus column to test as a feature downstream\n",
    "\n",
    "data['corpus'] = data['headline'] + ' ' + data['short_description']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove emojis and unicode chars\n",
    "#fxn from https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "\n",
    "def deEmojify(text):\n",
    "    regex = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regex.sub(r'',text)\n",
    "\n",
    "\n",
    "def deSymbolify(text):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    return regex.sub(r'', text)\n",
    "\n",
    "\n",
    "def dataframe_preprocess(col):\n",
    "    #tokenize into a new column\n",
    "    data[f'tokens_{col}'] = data[col].apply(nltk.word_tokenize)\n",
    "\n",
    "    #remove stop words\n",
    "    stopword = stopwords.words('english')\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [item for item in x if item not in stopword])\n",
    "\n",
    "    #remove symbols, non-ascii, digits, and too long and too short tokens\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [deSymbolify(word) for word in x])\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if word.isascii()==True])\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if not any(ch.isdigit() for ch in word)])\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) > 4])\n",
    "    data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) < 12])\n",
    "    \n",
    "    #add stemmed corpus column\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    data[f'stemmed_{col}'] = data[f'tokens_{col}'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    \n",
    "    #add lemmatized corpus\n",
    "    wnl = WordNetLemmatizer()\n",
    "    data[f'lemmatized_{col}'] = data[f'tokens_{col}'].apply(lambda x: [wnl.lemmatize(y) for y in x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.lower()\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(deEmojify)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[col].apply(nltk.word_tokenize)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [item for item in x if item not in stopword])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [deSymbolify(word) for word in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if word.isascii()==True])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if not any(ch.isdigit() for ch in word)])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) > 4])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) < 12])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'stemmed_{col}'] = data[f'tokens_{col}'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'lemmatized_{col}'] = data[f'tokens_{col}'].apply(lambda x: [wnl.lemmatize(y) for y in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.lower()\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(deEmojify)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[col].apply(nltk.word_tokenize)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [item for item in x if item not in stopword])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [deSymbolify(word) for word in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if word.isascii()==True])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if not any(ch.isdigit() for ch in word)])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) > 4])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) < 12])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'stemmed_{col}'] = data[f'tokens_{col}'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'lemmatized_{col}'] = data[f'tokens_{col}'].apply(lambda x: [wnl.lemmatize(y) for y in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.lower()\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].str.replace('[^\\w\\s]','')\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\2471050337.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(deEmojify)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[col].apply(nltk.word_tokenize)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [item for item in x if item not in stopword])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [deSymbolify(word) for word in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if word.isascii()==True])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if not any(ch.isdigit() for ch in word)])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) > 4])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'tokens_{col}'] = data[f'tokens_{col}'].apply(lambda x: [word for word in x if len(word) < 12])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'stemmed_{col}'] = data[f'tokens_{col}'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\4088668066.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'lemmatized_{col}'] = data[f'tokens_{col}'].apply(lambda x: [wnl.lemmatize(y) for y in x])\n"
     ]
    }
   ],
   "source": [
    "#text pre-processing for NLP use\n",
    "\n",
    "for col in ['category', 'headline', 'short_description', 'corpus']:\n",
    "    #Convert to lowercase\n",
    "    data[col] = data[col].str.lower()\n",
    "\n",
    "    #remove punctuation\n",
    "    data[col] = data[col].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    #get rid of unicode chars and any emojis\n",
    "    data[col] = data[col].apply(deEmojify)\n",
    "    \n",
    "    #tokenize, stem, and lemmatize \n",
    "    ## choice to not pre-process the category further as the values are usually unigrams or bigrams max\n",
    "    if col != 'category':\n",
    "        dataframe_preprocess(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics          26524\n",
       "entertainment     11117\n",
       "wellness           6092\n",
       "healthy living     5163\n",
       "travel             4168\n",
       "queer voices       3523\n",
       "parents            3495\n",
       "comedy             3239\n",
       "black voices       3238\n",
       "parenting          3238\n",
       "business           3144\n",
       "sports             3133\n",
       "women              3037\n",
       "food  drink        2692\n",
       "world news         2411\n",
       "style  beauty      2390\n",
       "media              2340\n",
       "the worldpost      2180\n",
       "impact             2106\n",
       "crime              2021\n",
       "weird news         1949\n",
       "green              1800\n",
       "style              1695\n",
       "religion           1675\n",
       "taste              1626\n",
       "home  living       1354\n",
       "worldpost          1253\n",
       "arts  culture      1197\n",
       "divorce            1163\n",
       "tech               1150\n",
       "good news          1112\n",
       "weddings           1039\n",
       "arts                995\n",
       "science             967\n",
       "latino voices       964\n",
       "college             866\n",
       "us news             863\n",
       "fifty               796\n",
       "education           701\n",
       "money               298\n",
       "environment          66\n",
       "culture  arts        49\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\560650356.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.category.replace(di, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "politics          26524\n",
       "entertainment     11117\n",
       "wellness           6092\n",
       "healthy living     5163\n",
       "travel             4168\n",
       "style              4085\n",
       "queer voices       3523\n",
       "parents            3495\n",
       "worldpost          3433\n",
       "comedy             3239\n",
       "parenting          3238\n",
       "black voices       3238\n",
       "business           3144\n",
       "sports             3133\n",
       "women              3037\n",
       "food drink         2692\n",
       "world news         2411\n",
       "media              2340\n",
       "impact             2106\n",
       "crime              2021\n",
       "weird news         1949\n",
       "green              1800\n",
       "religion           1675\n",
       "taste              1626\n",
       "home living        1354\n",
       "culture            1246\n",
       "divorce            1163\n",
       "tech               1150\n",
       "good news          1112\n",
       "weddings           1039\n",
       "arts                995\n",
       "science             967\n",
       "latino voices       964\n",
       "college             866\n",
       "us news             863\n",
       "fifty               796\n",
       "education           701\n",
       "money               298\n",
       "environment          66\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up redundant categories\n",
    "\n",
    "data.category.value_counts()\n",
    "\n",
    "di = {'food  drink': 'food drink',\n",
    "      'style  beauty': 'style',\n",
    "      'the worldpost': 'worldpost',\n",
    "      'arts  culture': 'culture',\n",
    "      'culture  arts': 'culture',\n",
    "      'home  living': 'home living'\n",
    "     }\n",
    "\n",
    "data.category.replace(di, inplace=True)\n",
    "\n",
    "data.category.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\252692635.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['year'] = data['date'].dt.year\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\252692635.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['month'] = data['date'].dt.month\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_22472\\252692635.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['day'] = data['date'].dt.day\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>returns</th>\n",
       "      <th>corpus</th>\n",
       "      <th>tokens_headline</th>\n",
       "      <th>stemmed_headline</th>\n",
       "      <th>lemmatized_headline</th>\n",
       "      <th>tokens_short_description</th>\n",
       "      <th>stemmed_short_description</th>\n",
       "      <th>lemmatized_short_description</th>\n",
       "      <th>tokens_corpus</th>\n",
       "      <th>stemmed_corpus</th>\n",
       "      <th>lemmatized_corpus</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>us news</td>\n",
       "      <td>over 4 million americans roll up sleeves for o...</td>\n",
       "      <td>health experts said it is too early to predict...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>over 4 million americans roll up sleeves for o...</td>\n",
       "      <td>[million, americans, sleeves, covid, boosters]</td>\n",
       "      <td>[million, american, sleev, covid, booster]</td>\n",
       "      <td>[million, american, sleeve, covid, booster]</td>\n",
       "      <td>[health, experts, early, predict, whether, dem...</td>\n",
       "      <td>[health, expert, earli, predict, whether, dema...</td>\n",
       "      <td>[health, expert, early, predict, whether, dema...</td>\n",
       "      <td>[million, americans, sleeves, covid, boosters,...</td>\n",
       "      <td>[million, american, sleev, covid, booster, hea...</td>\n",
       "      <td>[million, american, sleeve, covid, booster, he...</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>us news</td>\n",
       "      <td>american airlines flyer charged banned for lif...</td>\n",
       "      <td>he was subdued by passengers and crew when he ...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>american airlines flyer charged banned for lif...</td>\n",
       "      <td>[american, airlines, flyer, charged, banned, p...</td>\n",
       "      <td>[american, airlin, flyer, charg, ban, punch, f...</td>\n",
       "      <td>[american, airline, flyer, charged, banned, pu...</td>\n",
       "      <td>[subdued, passengers, aircraft, according, att...</td>\n",
       "      <td>[subdu, passeng, aircraft, accord, attorney, o...</td>\n",
       "      <td>[subdued, passenger, aircraft, according, atto...</td>\n",
       "      <td>[american, airlines, flyer, charged, banned, p...</td>\n",
       "      <td>[american, airlin, flyer, charg, ban, punch, f...</td>\n",
       "      <td>[american, airline, flyer, charged, banned, pu...</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>comedy</td>\n",
       "      <td>23 of the funniest tweets about cats and dogs ...</td>\n",
       "      <td>until you have a dog you dont understand what ...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>23 of the funniest tweets about cats and dogs ...</td>\n",
       "      <td>[funniest, tweets]</td>\n",
       "      <td>[funniest, tweet]</td>\n",
       "      <td>[funniest, tweet]</td>\n",
       "      <td>[understand, could, eaten]</td>\n",
       "      <td>[understand, could, eaten]</td>\n",
       "      <td>[understand, could, eaten]</td>\n",
       "      <td>[funniest, tweets, understand, could, eaten]</td>\n",
       "      <td>[funniest, tweet, understand, could, eaten]</td>\n",
       "      <td>[funniest, tweet, understand, could, eaten]</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>parenting</td>\n",
       "      <td>the funniest tweets from parents this week sep...</td>\n",
       "      <td>accidentally put grownup toothpaste on my todd...</td>\n",
       "      <td>3693.23</td>\n",
       "      <td>the funniest tweets from parents this week sep...</td>\n",
       "      <td>[funniest, tweets, parents]</td>\n",
       "      <td>[funniest, tweet, parent]</td>\n",
       "      <td>[funniest, tweet, parent]</td>\n",
       "      <td>[grownup, toothpaste, toddlers, toothbrush, sc...</td>\n",
       "      <td>[grownup, toothpast, toddler, toothbrush, scre...</td>\n",
       "      <td>[grownup, toothpaste, toddler, toothbrush, scr...</td>\n",
       "      <td>[funniest, tweets, parents, grownup, toothpast...</td>\n",
       "      <td>[funniest, tweet, parent, grownup, toothpast, ...</td>\n",
       "      <td>[funniest, tweet, parent, grownup, toothpaste,...</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>us news</td>\n",
       "      <td>woman who called cops on black birdwatcher los...</td>\n",
       "      <td>amy cooper accused investment firm franklin te...</td>\n",
       "      <td>3757.99</td>\n",
       "      <td>woman who called cops on black birdwatcher los...</td>\n",
       "      <td>[woman, called, black, birdwatcher, loses, law...</td>\n",
       "      <td>[woman, call, black, birdwatch, lose, lawsuit,...</td>\n",
       "      <td>[woman, called, black, birdwatcher, loses, law...</td>\n",
       "      <td>[cooper, accused, investment, franklin, temple...</td>\n",
       "      <td>[cooper, accus, invest, franklin, templeton, u...</td>\n",
       "      <td>[cooper, accused, investment, franklin, temple...</td>\n",
       "      <td>[woman, called, black, birdwatcher, loses, law...</td>\n",
       "      <td>[woman, call, black, birdwatch, lose, lawsuit,...</td>\n",
       "      <td>[woman, called, black, birdwatcher, loses, law...</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   category                                           headline  \\\n",
       "0 2022-09-23    us news  over 4 million americans roll up sleeves for o...   \n",
       "1 2022-09-23    us news  american airlines flyer charged banned for lif...   \n",
       "2 2022-09-23     comedy  23 of the funniest tweets about cats and dogs ...   \n",
       "3 2022-09-23  parenting  the funniest tweets from parents this week sep...   \n",
       "4 2022-09-22    us news  woman who called cops on black birdwatcher los...   \n",
       "\n",
       "                                   short_description  returns  \\\n",
       "0  health experts said it is too early to predict...  3693.23   \n",
       "1  he was subdued by passengers and crew when he ...  3693.23   \n",
       "2  until you have a dog you dont understand what ...  3693.23   \n",
       "3  accidentally put grownup toothpaste on my todd...  3693.23   \n",
       "4  amy cooper accused investment firm franklin te...  3757.99   \n",
       "\n",
       "                                              corpus  \\\n",
       "0  over 4 million americans roll up sleeves for o...   \n",
       "1  american airlines flyer charged banned for lif...   \n",
       "2  23 of the funniest tweets about cats and dogs ...   \n",
       "3  the funniest tweets from parents this week sep...   \n",
       "4  woman who called cops on black birdwatcher los...   \n",
       "\n",
       "                                     tokens_headline  \\\n",
       "0     [million, americans, sleeves, covid, boosters]   \n",
       "1  [american, airlines, flyer, charged, banned, p...   \n",
       "2                                 [funniest, tweets]   \n",
       "3                        [funniest, tweets, parents]   \n",
       "4  [woman, called, black, birdwatcher, loses, law...   \n",
       "\n",
       "                                    stemmed_headline  \\\n",
       "0         [million, american, sleev, covid, booster]   \n",
       "1  [american, airlin, flyer, charg, ban, punch, f...   \n",
       "2                                  [funniest, tweet]   \n",
       "3                          [funniest, tweet, parent]   \n",
       "4  [woman, call, black, birdwatch, lose, lawsuit,...   \n",
       "\n",
       "                                 lemmatized_headline  \\\n",
       "0        [million, american, sleeve, covid, booster]   \n",
       "1  [american, airline, flyer, charged, banned, pu...   \n",
       "2                                  [funniest, tweet]   \n",
       "3                          [funniest, tweet, parent]   \n",
       "4  [woman, called, black, birdwatcher, loses, law...   \n",
       "\n",
       "                            tokens_short_description  \\\n",
       "0  [health, experts, early, predict, whether, dem...   \n",
       "1  [subdued, passengers, aircraft, according, att...   \n",
       "2                         [understand, could, eaten]   \n",
       "3  [grownup, toothpaste, toddlers, toothbrush, sc...   \n",
       "4  [cooper, accused, investment, franklin, temple...   \n",
       "\n",
       "                           stemmed_short_description  \\\n",
       "0  [health, expert, earli, predict, whether, dema...   \n",
       "1  [subdu, passeng, aircraft, accord, attorney, o...   \n",
       "2                         [understand, could, eaten]   \n",
       "3  [grownup, toothpast, toddler, toothbrush, scre...   \n",
       "4  [cooper, accus, invest, franklin, templeton, u...   \n",
       "\n",
       "                        lemmatized_short_description  \\\n",
       "0  [health, expert, early, predict, whether, dema...   \n",
       "1  [subdued, passenger, aircraft, according, atto...   \n",
       "2                         [understand, could, eaten]   \n",
       "3  [grownup, toothpaste, toddler, toothbrush, scr...   \n",
       "4  [cooper, accused, investment, franklin, temple...   \n",
       "\n",
       "                                       tokens_corpus  \\\n",
       "0  [million, americans, sleeves, covid, boosters,...   \n",
       "1  [american, airlines, flyer, charged, banned, p...   \n",
       "2       [funniest, tweets, understand, could, eaten]   \n",
       "3  [funniest, tweets, parents, grownup, toothpast...   \n",
       "4  [woman, called, black, birdwatcher, loses, law...   \n",
       "\n",
       "                                      stemmed_corpus  \\\n",
       "0  [million, american, sleev, covid, booster, hea...   \n",
       "1  [american, airlin, flyer, charg, ban, punch, f...   \n",
       "2        [funniest, tweet, understand, could, eaten]   \n",
       "3  [funniest, tweet, parent, grownup, toothpast, ...   \n",
       "4  [woman, call, black, birdwatch, lose, lawsuit,...   \n",
       "\n",
       "                                   lemmatized_corpus  year  month  day  \n",
       "0  [million, american, sleeve, covid, booster, he...  2022      9   23  \n",
       "1  [american, airline, flyer, charged, banned, pu...  2022      9   23  \n",
       "2        [funniest, tweet, understand, could, eaten]  2022      9   23  \n",
       "3  [funniest, tweet, parent, grownup, toothpaste,...  2022      9   23  \n",
       "4  [woman, called, black, birdwatcher, loses, law...  2022      9   22  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split date predictor into elementary components\n",
    "\n",
    "data['year'] = data['date'].dt.year \n",
    "data['month'] = data['date'].dt.month \n",
    "data['day'] = data['date'].dt.day\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after manually reviewing records, choice to choose lemmatized over stemmed pre-processed text data to avoid nonsensical stems. also choosing to used a combined corpus per record rather than separate headline, short_description to limit the size of text vectors (avoid out of memory errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build actionable dataframe from data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized_headline</th>\n",
       "      <th>lemmatized_short_description</th>\n",
       "      <th>lemmatized_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>us news</td>\n",
       "      <td>million american sleeve covid booster</td>\n",
       "      <td>health expert early predict whether demand wou...</td>\n",
       "      <td>million american sleeve covid booster health e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>us news</td>\n",
       "      <td>american airline flyer charged banned punching...</td>\n",
       "      <td>subdued passenger aircraft according attorney ...</td>\n",
       "      <td>american airline flyer charged banned punching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>comedy</td>\n",
       "      <td>funniest tweet</td>\n",
       "      <td>understand could eaten</td>\n",
       "      <td>funniest tweet understand could eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>parenting</td>\n",
       "      <td>funniest tweet parent</td>\n",
       "      <td>grownup toothpaste toddler toothbrush screamed...</td>\n",
       "      <td>funniest tweet parent grownup toothpaste toddl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3757.99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>us news</td>\n",
       "      <td>woman called black birdwatcher loses lawsuit e...</td>\n",
       "      <td>cooper accused investment franklin templeton u...</td>\n",
       "      <td>woman called black birdwatcher loses lawsuit e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161346</th>\n",
       "      <td>1613.20</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>style</td>\n",
       "      <td>cheryl cole style evolution cornrows couture p...</td>\n",
       "      <td>cheryl cole wasnt exactly ordinary winning gir...</td>\n",
       "      <td>cheryl cole style evolution cornrows couture p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161347</th>\n",
       "      <td>1613.20</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>travel</td>\n",
       "      <td>three europe hedonistic city paris</td>\n",
       "      <td>paris brings season season</td>\n",
       "      <td>three europe hedonistic city paris paris bring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161348</th>\n",
       "      <td>1613.20</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>wellness</td>\n",
       "      <td>anxiety sleep deprivation</td>\n",
       "      <td>tease whether sleep simply byproduct anxiety w...</td>\n",
       "      <td>anxiety sleep deprivation tease whether sleep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161349</th>\n",
       "      <td>1613.20</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>food drink</td>\n",
       "      <td>cheese creation completely amazing</td>\n",
       "      <td>everything</td>\n",
       "      <td>cheese creation completely amazing everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161350</th>\n",
       "      <td>1613.20</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>wellness</td>\n",
       "      <td>stopping recognize liveoutloud youre living</td>\n",
       "      <td>recognize moment moment would treasure aware l...</td>\n",
       "      <td>stopping recognize liveoutloud youre living re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118829 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        returns  year  month  day    category  \\\n",
       "0       3693.23  2022      9   23     us news   \n",
       "1       3693.23  2022      9   23     us news   \n",
       "2       3693.23  2022      9   23      comedy   \n",
       "3       3693.23  2022      9   23   parenting   \n",
       "4       3757.99  2022      9   22     us news   \n",
       "...         ...   ...    ...  ...         ...   \n",
       "161346  1613.20  2013      6   27       style   \n",
       "161347  1613.20  2013      6   27      travel   \n",
       "161348  1613.20  2013      6   27    wellness   \n",
       "161349  1613.20  2013      6   27  food drink   \n",
       "161350  1613.20  2013      6   27    wellness   \n",
       "\n",
       "                                      lemmatized_headline  \\\n",
       "0                   million american sleeve covid booster   \n",
       "1       american airline flyer charged banned punching...   \n",
       "2                                          funniest tweet   \n",
       "3                                   funniest tweet parent   \n",
       "4       woman called black birdwatcher loses lawsuit e...   \n",
       "...                                                   ...   \n",
       "161346  cheryl cole style evolution cornrows couture p...   \n",
       "161347                 three europe hedonistic city paris   \n",
       "161348                          anxiety sleep deprivation   \n",
       "161349                 cheese creation completely amazing   \n",
       "161350        stopping recognize liveoutloud youre living   \n",
       "\n",
       "                             lemmatized_short_description  \\\n",
       "0       health expert early predict whether demand wou...   \n",
       "1       subdued passenger aircraft according attorney ...   \n",
       "2                                  understand could eaten   \n",
       "3       grownup toothpaste toddler toothbrush screamed...   \n",
       "4       cooper accused investment franklin templeton u...   \n",
       "...                                                   ...   \n",
       "161346  cheryl cole wasnt exactly ordinary winning gir...   \n",
       "161347                         paris brings season season   \n",
       "161348  tease whether sleep simply byproduct anxiety w...   \n",
       "161349                                         everything   \n",
       "161350  recognize moment moment would treasure aware l...   \n",
       "\n",
       "                                        lemmatized_corpus  \n",
       "0       million american sleeve covid booster health e...  \n",
       "1       american airline flyer charged banned punching...  \n",
       "2                   funniest tweet understand could eaten  \n",
       "3       funniest tweet parent grownup toothpaste toddl...  \n",
       "4       woman called black birdwatcher loses lawsuit e...  \n",
       "...                                                   ...  \n",
       "161346  cheryl cole style evolution cornrows couture p...  \n",
       "161347  three europe hedonistic city paris paris bring...  \n",
       "161348  anxiety sleep deprivation tease whether sleep ...  \n",
       "161349      cheese creation completely amazing everything  \n",
       "161350  stopping recognize liveoutloud youre living re...  \n",
       "\n",
       "[118829 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = data[['returns', 'year', 'month', 'day', 'category', \n",
    "           'lemmatized_headline', 'lemmatized_short_description', 'lemmatized_corpus']].copy(deep=True)\n",
    "\n",
    "#join tokens back together for final corpus\n",
    "for col in ['lemmatized_headline', 'lemmatized_short_description', 'lemmatized_corpus']:\n",
    "    df[col] = df[col].str.join(\" \")\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate records\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full text field as ML corpus\n",
    "df['corpus'] = df['category'] + ' ' + df['lemmatized_corpus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test 80:20 split\n",
    "\n",
    "df_train = df.sample(frac=0.80)\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='infrequent_if_exist')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encode the category predictor\n",
    "enc = OneHotEncoder(handle_unknown='infrequent_if_exist') #if a category arises that is not present in training, add to infrequent category\n",
    "\n",
    "enc.fit(df_train.category.to_numpy().reshape(-1, 1))\n",
    "\n",
    "#transform train and test separately\n",
    "df_train['category_enc'] = list(np.array(enc.transform(df_train.category.to_numpy().reshape(-1, 1)).todense()))\n",
    "df_test['category_enc'] = list(np.array(enc.transform(df_test.category.to_numpy().reshape(-1, 1)).todense()))\n",
    "\n",
    "df_train = df_train[['returns', 'year', 'month', 'day', 'category_enc', 'corpus']]\n",
    "df_test = df_test[['returns', 'year', 'month', 'day', 'category_enc', 'corpus']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95042, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category_enc</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32714</th>\n",
       "      <td>2440.35</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>black voices kerry washington artist doesnt vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82235</th>\n",
       "      <td>2090.11</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>worldpost world leader build momentum paris cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40611</th>\n",
       "      <td>2365.45</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>politics going backward american insurance dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105341</th>\n",
       "      <td>2044.16</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>worldpost white house need support egypt jorda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96210</th>\n",
       "      <td>2124.20</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>college south carolina college president call ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        returns  year  month  day  \\\n",
       "32714   2440.35  2017      6   13   \n",
       "82235   2090.11  2015     11   27   \n",
       "40611   2365.45  2017      3   14   \n",
       "105341  2044.16  2015      3   10   \n",
       "96210   2124.20  2015      6   23   \n",
       "\n",
       "                                             category_enc  \\\n",
       "32714   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "82235   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "40611   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "105341  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96210   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                   corpus  \n",
       "32714   black voices kerry washington artist doesnt vo...  \n",
       "82235   worldpost world leader build momentum paris cl...  \n",
       "40611   politics going backward american insurance dec...  \n",
       "105341  worldpost white house need support egypt jorda...  \n",
       "96210   college south carolina college president call ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(23760, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category_enc</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>comedy funniest tweet understand could eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3757.99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>world news puerto ricans desperate water hurri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3757.99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>culture documentary capture complexity child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3855.93</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sports maury will shortstop dodger maury will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3855.93</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>entertainment golden globe returning january o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    returns  year  month  day  \\\n",
       "2   3693.23  2022      9   23   \n",
       "7   3757.99  2022      9   22   \n",
       "8   3757.99  2022      9   22   \n",
       "17  3855.93  2022      9   20   \n",
       "20  3855.93  2022      9   20   \n",
       "\n",
       "                                         category_enc  \\\n",
       "2   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               corpus  \n",
       "2        comedy funniest tweet understand could eaten  \n",
       "7   world news puerto ricans desperate water hurri...  \n",
       "8   culture documentary capture complexity child i...  \n",
       "17  sports maury will shortstop dodger maury will ...  \n",
       "20  entertainment golden globe returning january o...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "df_train.head()\n",
    "\n",
    "df_test.shape\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction\n",
    "\n",
    "TF-IDF is used as the feature extraction for a few reasons:\n",
    "\n",
    "1. bag of words will not capture the higher dimension interaction space of tokens and n-grams\n",
    "2. word2vec and BERT are great for ANN applications and large corpuses. This is a rather small corpus in the NLP world and the goal is not necessarily to train a neural network over simpler model types, so large embedding spaces are not a hard requirement for this task.\n",
    "\n",
    "Choice to vectorize as unigrams in order to avoid MemoryErrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85538, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category_enc</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44250</th>\n",
       "      <td>2279.55</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>black voices twitter imago trump white house c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88739</th>\n",
       "      <td>1995.31</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>politics union chief call james blake arrest c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130721</th>\n",
       "      <td>1900.53</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>women swimsuit guide woman swimsuit guide they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129308</th>\n",
       "      <td>1951.27</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>latino voices sanction sanction forget leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96784</th>\n",
       "      <td>2100.44</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sports beyond number boston olympic opportunit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        returns  year  month  day  \\\n",
       "44250   2279.55  2017      2    1   \n",
       "88739   1995.31  2015      9   16   \n",
       "130721  1900.53  2014      5   23   \n",
       "129308  1951.27  2014      6    9   \n",
       "96784   2100.44  2015      6   17   \n",
       "\n",
       "                                             category_enc  \\\n",
       "44250   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "88739   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "130721  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "129308  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "96784   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                   corpus  \n",
       "44250   black voices twitter imago trump white house c...  \n",
       "88739   politics union chief call james blake arrest c...  \n",
       "130721  women swimsuit guide woman swimsuit guide they...  \n",
       "129308  latino voices sanction sanction forget leading...  \n",
       "96784   sports beyond number boston olympic opportunit...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9504, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category_enc</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95435</th>\n",
       "      <td>2076.78</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>women resilience overcome stress stress listen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76766</th>\n",
       "      <td>1940.24</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sports gotcha charger diego charger battle con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136179</th>\n",
       "      <td>1866.52</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>food drink grass regular taste better burger s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141559</th>\n",
       "      <td>1828.46</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>divorce dating process process begin first lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115743</th>\n",
       "      <td>2038.26</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>parents smile goofy mouthwide handing pediatri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        returns  year  month  day  \\\n",
       "95435   2076.78  2015      7    2   \n",
       "76766   1940.24  2016      1   29   \n",
       "136179  1866.52  2014      3   21   \n",
       "141559  1828.46  2014      1   23   \n",
       "115743  2038.26  2014     11   10   \n",
       "\n",
       "                                             category_enc  \\\n",
       "95435   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "76766   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "136179  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "141559  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "115743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                   corpus  \n",
       "95435   women resilience overcome stress stress listen...  \n",
       "76766   sports gotcha charger diego charger battle con...  \n",
       "136179  food drink grass regular taste better burger s...  \n",
       "141559  divorce dating process process begin first lik...  \n",
       "115743  parents smile goofy mouthwide handing pediatri...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train validation 90:10 split\n",
    "\n",
    "df_training = df_train.sample(frac=0.90)\n",
    "df_val = df_train.drop(df_training.index)\n",
    "\n",
    "df_training.shape\n",
    "df_training.head()\n",
    "df_val.shape\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95042"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create master training corpus\n",
    "corpus = (df_train['corpus']).to_list()\n",
    "\n",
    "len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF vectorization\n",
    "#strip any remaining unicode characters and set n-gram range\n",
    "tfidf = TfidfVectorizer(strip_accents='unicode', ngram_range=(1,1), use_idf=True)\n",
    "fit_tfidf = tfidf.fit(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit TFIDF to vectorize training and validation sets\n",
    "\n",
    "vectors_train = fit_tfidf.transform(df_training['corpus'].to_list())\n",
    "vectors_val = fit_tfidf.transform(df_val['corpus'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaaah</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaargh</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aakayla</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aakomon</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaliyah</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwirner</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwirners</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyola</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyrtec</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzgah</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50443 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tfidf\n",
       "aaaaaah      0.0\n",
       "aaaargh      0.0\n",
       "aakayla      0.0\n",
       "aakomon      0.0\n",
       "aaliyah      0.0\n",
       "...          ...\n",
       "zwirner      0.0\n",
       "zwirners     0.0\n",
       "zyola        0.0\n",
       "zyrtec       0.0\n",
       "zzzzzzgah    0.0\n",
       "\n",
       "[50443 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "pd.DataFrame(vectors_train[0].T.todense(), index=tfidf.get_feature_names_out(), columns=[\"tfidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectors_train.toarray()\n",
    "X_val = vectors_val.toarray()\n",
    "y_train = df_training['returns'].to_numpy()\n",
    "y_val = df_val['returns'].to_numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf.vocabulary_ #justincase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply feature extractions to test set based on trained tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>category_enc</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3693.23</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>comedy funniest tweet understand could eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3757.99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>world news puerto ricans desperate water hurri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3757.99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>culture documentary capture complexity child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3855.93</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sports maury will shortstop dodger maury will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3855.93</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>entertainment golden globe returning january o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    returns  year  month  day  \\\n",
       "2   3693.23  2022      9   23   \n",
       "7   3757.99  2022      9   22   \n",
       "8   3757.99  2022      9   22   \n",
       "17  3855.93  2022      9   20   \n",
       "20  3855.93  2022      9   20   \n",
       "\n",
       "                                         category_enc  \\\n",
       "2   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               corpus  \n",
       "2        comedy funniest tweet understand could eaten  \n",
       "7   world news puerto ricans desperate water hurri...  \n",
       "8   culture documentary capture complexity child i...  \n",
       "17  sports maury will shortstop dodger maury will ...  \n",
       "20  entertainment golden globe returning january o...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23760"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = df_test['corpus'].to_list()\n",
    "\n",
    "len(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_test = fit_tfidf.transform(df_test['corpus'].to_list())\n",
    "\n",
    "X_test = vectors_test.toarray()\n",
    "y_test = df_test['returns'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "How do the non corpus predictors fare in a penalized regression to predict S&P returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_21012\\4172150398.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_train.corr().style.background_gradient(cmap='coolwarm', vmin=-1, vmax=1).set_precision(2)\n",
      "C:\\Users\\alxra\\AppData\\Local\\Temp\\ipykernel_21012\\4172150398.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  df_train.corr().style.background_gradient(cmap='coolwarm', vmin=-1, vmax=1).set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f824e_row0_col0, #T_f824e_row1_col1, #T_f824e_row2_col2, #T_f824e_row3_col3 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f824e_row0_col1, #T_f824e_row1_col0 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f824e_row0_col2, #T_f824e_row2_col0 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f824e_row0_col3, #T_f824e_row3_col0 {\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f824e_row1_col2, #T_f824e_row2_col1 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f824e_row1_col3, #T_f824e_row3_col1 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f824e_row2_col3, #T_f824e_row3_col2 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f824e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f824e_level0_col0\" class=\"col_heading level0 col0\" >returns</th>\n",
       "      <th id=\"T_f824e_level0_col1\" class=\"col_heading level0 col1\" >year</th>\n",
       "      <th id=\"T_f824e_level0_col2\" class=\"col_heading level0 col2\" >month</th>\n",
       "      <th id=\"T_f824e_level0_col3\" class=\"col_heading level0 col3\" >day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f824e_level0_row0\" class=\"row_heading level0 row0\" >returns</th>\n",
       "      <td id=\"T_f824e_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_f824e_row0_col1\" class=\"data row0 col1\" >0.91</td>\n",
       "      <td id=\"T_f824e_row0_col2\" class=\"data row0 col2\" >-0.06</td>\n",
       "      <td id=\"T_f824e_row0_col3\" class=\"data row0 col3\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f824e_level0_row1\" class=\"row_heading level0 row1\" >year</th>\n",
       "      <td id=\"T_f824e_row1_col0\" class=\"data row1 col0\" >0.91</td>\n",
       "      <td id=\"T_f824e_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_f824e_row1_col2\" class=\"data row1 col2\" >-0.23</td>\n",
       "      <td id=\"T_f824e_row1_col3\" class=\"data row1 col3\" >-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f824e_level0_row2\" class=\"row_heading level0 row2\" >month</th>\n",
       "      <td id=\"T_f824e_row2_col0\" class=\"data row2 col0\" >-0.06</td>\n",
       "      <td id=\"T_f824e_row2_col1\" class=\"data row2 col1\" >-0.23</td>\n",
       "      <td id=\"T_f824e_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_f824e_row2_col3\" class=\"data row2 col3\" >-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f824e_level0_row3\" class=\"row_heading level0 row3\" >day</th>\n",
       "      <td id=\"T_f824e_row3_col0\" class=\"data row3 col0\" >-0.00</td>\n",
       "      <td id=\"T_f824e_row3_col1\" class=\"data row3 col1\" >-0.02</td>\n",
       "      <td id=\"T_f824e_row3_col2\" class=\"data row3 col2\" >-0.01</td>\n",
       "      <td id=\"T_f824e_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ed9afd52a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation\n",
    "df_train.corr().style.background_gradient(cmap='coolwarm', vmin=-1, vmax=1).set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "year is highly correlated with S&P returns, but month and day are not. This may indicate that date is not sufficient to predict returns alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNetCV(cv=10, random_state=47)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNetCV</label><div class=\"sk-toggleable__content\"><pre>ElasticNetCV(cv=10, random_state=47)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNetCV(cv=10, random_state=47)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8226728807944109"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8181590873887096"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## date features\n",
    "# ElasticNet (L1, L2) regression with 10 fold cross validation\n",
    "\n",
    "regr = ElasticNetCV(cv=10, random_state=47)\n",
    "regr.fit(df_training[['year', 'month', 'day']].to_numpy(), y_train)\n",
    "\n",
    "#validate - coef of determination R2\n",
    "regr.score(df_val[['year', 'month', 'day']].to_numpy(), y_val)\n",
    "\n",
    "#test - coef of determination R2\n",
    "regr.score(df_test[['year', 'month', 'day']].to_numpy(), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using date parts alone, an elastic net regression that regularizes predictors by shrinkage predicts on the validation and test datasets with a Coefficient of Determination at ~ 0.82 regarding the input date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNetCV(cv=10, random_state=47)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNetCV</label><div class=\"sk-toggleable__content\"><pre>ElasticNetCV(cv=10, random_state=47)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNetCV(cv=10, random_state=47)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1806686235894004"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.17709845285778514"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##categorical onehot encoding\n",
    "\n",
    "# ElasticNet (L1, L2) regression with 10 fold cross validation\n",
    "\n",
    "regr = ElasticNetCV(cv=10, random_state=47)\n",
    "regr.fit(df_training['category_enc'].to_list(), y_train)\n",
    "\n",
    "#validate - coef of determination R2\n",
    "regr.score(df_val['category_enc'].to_list(), y_val)\n",
    "\n",
    "#test - coef of determination R2\n",
    "regr.score(df_test['category_enc'].to_list(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using categorical onehot encoding alone is insufficient for predicting S&P returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNetCV(cv=10, random_state=47)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNetCV</label><div class=\"sk-toggleable__content\"><pre>ElasticNetCV(cv=10, random_state=47)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNetCV(cv=10, random_state=47)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8228182848974891"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8183309715701851"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##date and categorical onehot encoding together\n",
    "\n",
    "# ElasticNet (L1, L2) regression with 10 fold cross validation\n",
    "\n",
    "regr = ElasticNetCV(cv=10, random_state=47)\n",
    "regr.fit(np.concatenate([df_training[['year', 'month', 'day']].to_numpy(), df_training['category_enc'].to_list()], axis=1), y_train)\n",
    "\n",
    "#validate - coef of determination R2\n",
    "regr.score(np.concatenate([df_val[['year', 'month', 'day']].to_numpy(), df_val['category_enc'].to_list()], axis=1), y_val)\n",
    "\n",
    "#test - coef of determination R2\n",
    "regr.score(np.concatenate([df_test[['year', 'month', 'day']].to_numpy(), df_test['category_enc'].to_list()], axis=1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using date parts together with the categorical encoding does not help to improve predictor performance given regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-5.476625958388923e+22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression\n",
    "\n",
    "reg = LinearRegression()\n",
    "# reg.fit(X_train, y_train)\n",
    "\n",
    "reg.fit(X_val, y_val)\n",
    "\n",
    "reg.score(X_test, y_test) #R2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible prediction using text data to train a ordinary least squares regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alxra\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1551: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(random_state=47)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(random_state=47)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(random_state=47)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.30815385794393013"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stochastic Gradient Descent regression\n",
    "\n",
    "reg = SGDRegressor(max_iter=1000, tol=1e-3, random_state=47)\n",
    "\n",
    "reg.fit(X_val, y_val)\n",
    "\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved predictive power using an SDG regressor to predict returns from text data but the Coef of Determination is still too low to be a reliable predictor. I would like to see >0.6 at least for R^2. Additionally these sklearn models take too long to train on huge matrix data so I had to use the small validation set to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 28s]\n",
      "val_loss: 186560.96875\n",
      "\n",
      "Best val_loss So Far: 132005.59375\n",
      "Total elapsed time: 00h 02m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "297/297 [==============================] - 8s 23ms/step - loss: 1062716.2500 - mean_squared_error: 1062716.2500 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "297/297 [==============================] - 7s 24ms/step - loss: 519751.4375 - mean_squared_error: 519751.4375 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "297/297 [==============================] - 8s 26ms/step - loss: 465490.2188 - mean_squared_error: 465490.2188 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "297/297 [==============================] - 7s 23ms/step - loss: 438445.9375 - mean_squared_error: 438445.9375 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "297/297 [==============================] - 7s 23ms/step - loss: 413521.1250 - mean_squared_error: 413521.1250 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\trainset_test\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\trainset_test\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2579a9ff010>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743/743 [==============================] - 2s 3ms/step - loss: 139907.1094 - mean_squared_error: 139907.1094 - accuracy: 0.0000e+00\n",
      "[139907.109375, 139907.109375, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#autokeras -trying an OOB search btw 5 text regressor architectures by Keras\n",
    "\n",
    "reg = ak.TextRegressor(project_name='trainset_test', overwrite=True, max_trials=5, metrics=['mean_squared_error',\n",
    "                                                                                            'accuracy'])\n",
    "reg.fit(df_val['corpus'].to_numpy(), y_val, epochs=5, shuffle=True, validation_split=0.1)\n",
    "\n",
    "print(reg.evaluate(df_test['corpus'].to_numpy(), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loss is much larger than validation loss, indicating that training is insufficient to generalize well while predicting on unseen data. these models are computationally expensive, I would re-run these on GPU if using AutoKeras again. I also can't recover the assets file that contains the plain text description of the best model from the trials - when using conda+jupyter, the files saved by AutoKeras are not utf-8 encoded and thus have saving disabled.\n",
    "\n",
    "Not an improvement over the SDG regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "268/268 [==============================] - 14s 49ms/step - loss: 1054927.5000 - accuracy: 0.0000e+00 - val_loss: 152292.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 167652.4531 - accuracy: 0.0000e+00 - val_loss: 142208.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 134390.8125 - accuracy: 0.0000e+00 - val_loss: 151755.6250 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1054927.5, 167652.453125, 134390.8125],\n",
       " 'accuracy': [0.0, 0.0, 0.0],\n",
       " 'val_loss': [152292.6875, 142208.453125, 151755.625],\n",
       " 'val_accuracy': [0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "#train and store history\n",
    "History = model.fit(x=X_val, y=y_val, epochs=3, validation_split=0.1, shuffle=True, verbose=1)\n",
    "History.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a very dense network that is regularized is an improvement over the AutoKeras neural network in terms of training and validation losses.\n",
    "\n",
    "With more time, this is something I would train into the ground to minimize loss and definitely experiment with the funnel architecture and testing initializers to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743/743 [==============================] - 9s 12ms/step - loss: 160175.5469 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "modeleval = model.evaluate(X_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test loss is higher with the current DNN architecture compared to autokeras but not by much. This DNN is a much simpler architecture and required less training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Based on these experiments, complex models such as neural networks are necessary in predicting S&P500 returns from Huff Post News text data. AutoKeras may be an option as it does not require as much data preprocessing and can run tens of hundreds of experiments while tracking without user intervention. Tensorflow and Keras may be a strong contender since customization of the layers allows for fine-tuned training and regularization.\n",
    "\n",
    "\n",
    "Simpler regression models such as ElasticNet can predict returns from date part news data, however the drop in test coefficient of determination suggests that this model may not generalize well.\n",
    "\n",
    "A more advanced regression model such as SDG does show promise as a returns predictor using text data input if a larger training set and more epochs are employed.\n",
    "\n",
    "* Huff Post News Category alone cannot predict S&P\n",
    "* Year of news publication is highly correlated with S&P returns, and using the date parts as features for a linear regression (regularized) may be a useful predictive tool given Huff Post data.\n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "I was severely limited by memory and hardware, which is fine for running outside of a cloud env as I did here but I typically do not fully train on my local machine for staging or production deploys.\n",
    "\n",
    "\n",
    "## Future Work\n",
    "\n",
    "I would like to collect more data from different news sources to reduce bias. I would further experiment with n-gram size, since increasing the n-gram size posed memory issue. Given that the training corpus would increase with more news sources, I would propose using word2vec or BERT embeddings instead of TF-IDF to handle the larger dimensionality and most likely better train complex networks, which for this NLP task are necessary compared to simple regressors.\n",
    "\n",
    "I would experiment more with the custom neural network architecture, adding LSTM or 1-D CNN layers and trying different layer activations. In the background I would run a larger AutoKeras experiment but would not use this over a custom architecture for production since I do not have all the metadata on the underlying model.\n",
    "\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "I enjoyed doing an NLP regression task as I typically am building for sentiment analysis or recommendation systems in the NLP space that lean more on the classification side. I focused primarily on the data ingestion, cleaning and processing as I believe in 'garbage in, garbage out' with models; my specialization in AI is in model architecture but I know I can't trust the performance of anything I build unless I am certain the underlying data is prepped to be actionable. I also wanted to highlight the scientist aspect of myself, where I chose to experiment with models and features rather than drilling down on a particular arbitrarily chosen set first. This is how I work whether I am at the computer or wet bench when working on something previously unreported: I run a set of quick yet robust experiments that I know I can accurately/reproducibly measure success and loss from, increasing model or experiment sophistication incremently based on the outcomes of the last. Then when I narrow down one or two models that seem optimal, I drill down regularization parameters and tune the architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
